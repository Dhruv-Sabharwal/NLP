{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "import os\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "'''\n",
    "# Use this to download parts of speech tagging model\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the adjectives from the reviews\n",
    "def get_adjectives(words):\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    words=[]\n",
    "    for i in range(len(tagged_words)):\n",
    "        if(tagged_words[i][0] not in stopwords and tagged_words[i][1] == 'JJ'): # removing stopwords and considering only adjectives\n",
    "            words.append(tagged_words[i][0])\n",
    "    return words\n",
    "\n",
    "# normalize, remove punctuation, lemmatize and tokenize\n",
    "def basic_clean(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore')\n",
    "    .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    words = get_adjectives(words)\n",
    "    return [wnl.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the reviews from the files\n",
    "pos_files = os.listdir('aclImdb/train/pos')\n",
    "neg_files = os.listdir('aclImdb/train/neg')\n",
    "pos_reviews = []\n",
    "for f in pos_files:\n",
    "    pos_reviews.append(basic_clean(open('aclImdb/train/pos/' + f, 'r', encoding=\"utf8\").read()))   \n",
    "neg_reviews = []\n",
    "for f in neg_files:\n",
    "    neg_reviews.append(basic_clean(open('aclImdb/train/neg/' + f, 'r', encoding=\"utf8\").read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515683\n"
     ]
    }
   ],
   "source": [
    "# Accumulating all possible adjectives into list vocab\n",
    "vocab = []\n",
    "for review in pos_reviews:\n",
    "    for word in review:    \n",
    "        vocab.append(word)        \n",
    "for review in neg_reviews:\n",
    "    for word in review:    \n",
    "        vocab.append(word)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "# creating a frequency distribution of the combined vocabulary of adjectives\n",
    "distribution = nltk.FreqDist(vocab)\n",
    "\n",
    "# taking the 2000 most frequent adjectives\n",
    "most_freq = distribution.most_common(2000)\n",
    "\n",
    "# creating a list of just the most frequent adjectives from the frequency distribution\n",
    "most_frequent_adjectives = []\n",
    "for word in most_freq:\n",
    "    most_frequent_adjectives.append(word[0])\n",
    "    \n",
    "print(len(most_frequent_adjectives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building features for the naive bayes classifier\n",
    "def get_features(review):\n",
    "    features = {}\n",
    "    for w in most_frequent_adjectives:\n",
    "        features[w] = (w in review)\n",
    "    return features\n",
    "\n",
    "\n",
    "'''\n",
    "Preparing training data.\n",
    "The training data is a list of tuples. Every tuple has a dictionary as it's first element and either 'pos'\n",
    "or 'neg' as it's second element.\n",
    "The dictionary is the features i.e. the dictionary is of the form {'boring': True, 'bad': True, 'fun': False, ...... }\n",
    "showing which all words from the vocabulary are present in that particular review.\n",
    "'''\n",
    "train_set = []\n",
    "for i in range(len(pos_reviews)):\n",
    "    train_set.append((get_features(pos_reviews[i]), 'pos'))\n",
    "for i in range(len(neg_reviews)):\n",
    "    train_set.append((get_features(neg_reviews[i]), 'neg'))\n",
    "    \n",
    "random.shuffle(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting a Naive Bayes Classifier on the data\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading testing data\n",
    "pos_files_test = os.listdir('aclImdb/test/pos')\n",
    "neg_files_test = os.listdir('aclImdb/test/neg')\n",
    "pos_reviews_test = []\n",
    "for f in pos_files_test:\n",
    "    pos_reviews_test.append(basic_clean(open('aclImdb/test/pos/' + f, 'r', encoding=\"utf8\").read()))   \n",
    "neg_reviews_test = []\n",
    "for f in neg_files_test:\n",
    "    neg_reviews_test.append(basic_clean(open('aclImdb/test/neg/' + f, 'r', encoding=\"utf8\").read()))\n",
    "    \n",
    "# preparing testing data\n",
    "test_set = []\n",
    "for i in range(len(pos_reviews_test)):\n",
    "    test_set.append((get_features(pos_reviews_test[i]), 'pos'))\n",
    "for i in range(len(neg_reviews_test)):\n",
    "    test_set.append((get_features(neg_reviews_test[i]), 'neg'))\n",
    "\n",
    "random.shuffle(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating accuracy\n",
    "#print(\"Classifier accuracy:\", (nltk.classify.accuracy(classifier, test_set)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     uwe = True              neg : pos    =     33.7 : 1.0\n",
      "             unwatchable = True              neg : pos    =     26.7 : 1.0\n",
      "                 awfulbr = True              neg : pos    =     23.7 : 1.0\n",
      "              incoherent = True              neg : pos    =     19.7 : 1.0\n",
      "                  poorly = True              neg : pos    =     19.0 : 1.0\n",
      "             influential = True              pos : neg    =     14.6 : 1.0\n",
      "                  flimsy = True              neg : pos    =     13.8 : 1.0\n",
      "                 unfunny = True              neg : pos    =     13.6 : 1.0\n",
      "               redeeming = True              neg : pos    =     13.2 : 1.0\n",
      "             astonishing = True              pos : neg    =     13.0 : 1.0\n",
      "                     bug = True              pos : neg    =     13.0 : 1.0\n",
      "                   worst = True              neg : pos    =     12.6 : 1.0\n",
      "                  seagal = True              neg : pos    =     12.6 : 1.0\n",
      "               firstrate = True              pos : neg    =     12.2 : 1.0\n",
      "                 harriet = True              pos : neg    =     12.2 : 1.0\n",
      "                   inane = True              neg : pos    =     12.2 : 1.0\n",
      "                godawful = True              neg : pos    =     11.0 : 1.0\n",
      "                stupidbr = True              neg : pos    =     11.0 : 1.0\n",
      "                 vacuous = True              neg : pos    =     11.0 : 1.0\n",
      "                flawless = True              pos : neg    =     11.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding predictions on test_set\n",
    "preds = []\n",
    "ground_truth = []\n",
    "for i in range(len(test_set)):\n",
    "    preds.append(classifier.classify(test_set[i][0]))\n",
    "    ground_truth.append(test_set[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the goodness figures\n",
    "def goodness_figures(ground_truth, preds):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    ACC = 0\n",
    "    for i in range(len(preds)): \n",
    "        if ground_truth[i]==preds[i]=='pos':\n",
    "           TP += 1\n",
    "           ACC +=1\n",
    "        if preds[i]=='pos' and ground_truth[i]=='neg':\n",
    "           FP += 1\n",
    "        if ground_truth[i]==preds[i]=='neg':\n",
    "           TN += 1\n",
    "           ACC +=1\n",
    "        if preds[i]=='neg' and ground_truth[i]=='pos':\n",
    "           FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN, ACC/len(preds)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives:  9678\n",
      "False Positives:  2107\n",
      "True Negatives:  10393\n",
      "False Negatives:  2822\n",
      "Accuracy:  80.284 %\n"
     ]
    }
   ],
   "source": [
    "scores = goodness_figures(ground_truth, preds)\n",
    "print(\"True Positives: \", scores[0])\n",
    "print(\"False Positives: \", scores[1])\n",
    "print(\"True Negatives: \", scores[2])\n",
    "print(\"False Negatives: \", scores[3])\n",
    "print(\"Accuracy: \", scores[4], \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
